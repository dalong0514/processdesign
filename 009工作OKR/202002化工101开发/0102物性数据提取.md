# 物性数据

## 01. 物性数据

### 1. 危化品数据

从 word 里提取表格数据。

```py
# -*- coding:utf-8 -*-

from io import StringIO
import json, time, os.path, re, glob

import numpy as np
import pandas as pd
from sqlalchemy import create_engine
import docx
from docx import Document

def get_docxtable():
    """获取 word 内 table 数据"""
    document = Document('material.docx')
    tables = document.tables
    table = tables[0]

    materials = []

    for i in range(1, len(table.rows)):
        material = {}
        material['id'] = table.cell(i,0).text
        material['name'] = table.cell(i,1).text
        material['alisname'] = table.cell(i,2).text
        material['englishname'] = table.cell(i,3).text
        material['cas'] = table.cell(i,4).text
        material['hazard'] = table.cell(i,5).text
        material['comment'] = table.cell(i,6).text
        materials.append(material)

    # with open('materialdata.json', 'w',  encoding='utf-8') as f:
    with open('materialdata.json', 'w') as f:
        json.dump(materials, f)

    # 存储为 json 数据
    with open('data.json', 'w') as f:
        json.dump(materials, f)
    
    # 转成 dataframe 格式
    df = pd.read_json("data.json",encoding="utf-8", orient='records')

    # 写数据
    engine = create_engine('mysql+pymysql://root@localhost:3306/pandasdata')
    df.to_sql('materialdata', engine, index= False)

if __name__ == '__main__':
    time_start = time.time()

    try:
        get_docxtable()
    except Exception as e:
        print('Error: ' + e)

    time_end = time.time()
    print('Time Used: ' + str(time_end-time_start) + 's')

```

### 1. 重点监管物质

```py
def get_supervisedata():
    """获取重点监管物质数据"""
    document = Document('zhongdian.docx')
    tables = document.tables

    materials = []
    for table in tables:
        material = {}
        material['special_warn'] = table.cell(0,1).text
        material['physical_property'] = table.cell(1,1).text
        material['harm_info'] = table.cell(2,1).text
        material['safety_precaution'] = table.cell(3,1).text
        material['emergency'] = table.cell(4,1).text
        materials.append(material)

    with open('supervisedata.json', 'w', encoding='utf-8') as f:
        json.dump(materials, f)
```

进 jupyter 里操作。

```
df = pd.read_json("supervisedata.json",encoding="utf-8", orient='records')
df.index = list(range(1,df.shape[0]+1))
df = df.reset_index()
df = df.rename(columns={'index':'supervise_id'})

# 增加危化品序号字段
data = pd.merge(df, df1, on='supervise_id', how='outer')

df.to_csv('supervisedata.csv', index=False)

# 与原有数据合并
df = pd.merge(df, data, on='id', how='outer')
df = df.drop_duplicates(['id'])

df.to_csv('20200413property.csv', index=False)

# 通过判断是否为空值选择性的赋值
df['supervise_status'] = df['supervise_id'].apply(lambda x: 0 if pd.isna(x) else 1)

# 合并两列的字符串
df.loc[:,'emergency'] = df['emergency_y'].astype('str') + df['emergency_x'].astype('str')

# 写数据
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://root@localhost:3306/shop')
df.to_sql('tz_property', engine, index= False)
```

## 02. 过程中遇到的问题

### 01

word 要另存为 2007 版的 docx 文件，否则读不出来。

官方文档有关表格的知识：[Quickstart — python-docx 0.8.10 documentation](https://python-docx.readthedocs.io/en/latest/user/quickstart.html)。

### 02

json 转成 dataframe 格式数据有很多知识点。

[python中基于pandas模块：json与dataframe的互相转换_Python_theskylife的博客-CSDN博客](https://blog.csdn.net/qq_41780234/article/details/84990551)

[pandas.read_json — pandas 1.0.3 documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html#pandas.read_json)

当我们在进行数据分析的时候，经常会遇到各种各样格式的文件，今天在这里整理一下对于 json 格式的文件怎么转化为 dataframe 的形式的文件。

1、对于简单的 json 形式。所谓的简单的 json 格式，就是将字典形式的文件，直接输出成 dataframe 形式的文件。test.json：

```py
obj="""[{"姓名": "张三",
 "住处": "天朝",
 "宠物": "koala",
 "兄弟": "李四"
},{"姓名": "李四",
 "住处": "天朝",
 "宠物": "cat",
 "兄弟": "张三"}]"""

with open("test.json","w",encoding="utf-8") as f:
    f.write(obj)
```

利用 pandas 自带的 read_json 直接解析字符串。

```py
import pandas as pd
df = pd.read_json("test.json",encoding="utf-8", orient='records')
print(df)
```

利用 json 库 loads 方法和 pandas 库中的 json_normalize 方法。

```py
import json 
from pandas.io.json import json_normalize
data=open("test.json",encoding="utf-8").read()
data_list = json.loads(data)
df = json_normalize(data_list)
print(df)
```

2、对于稍微复杂一些的 json 进行处理。复杂的一些的 json 格式的文件，例子如下，我们想要得到的数据是张三兄弟的数据，同样先写入 json 文件：

```py
obj = """
{"姓名": "张三",
 "住处": ["天朝", "岛国", "万恶的资本主义日不落帝国"],
 "宠物": null,
 "兄弟": [{"姓名": "李四", "年龄": 25, "宠物": "汪星人"},
              {"姓名": "王五", "年龄": 23, "宠物": "喵星人"}]
}"""
with open("test1.json","w",encoding="utf-8") as f:
    f.write(obj)
```

利用 json 的 loads 和 pandas 的 DataFrame。

```py
import json 
import pandas as pd
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    df=pd.DataFrame(brother_info)
#     print(type(brother_info))
#     print(brother_info)
#     print(brother_info)
```

利用 json 的 loads 和 pandas 的 json_normalize。

```py
from pandas.io.json import json_normalize
import json 
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    df = json_normalize(brother_info)
    print(df)
```

利用 json 的 loads 和 pandas 的 read_json。

```py
import json 
import pandas as pd
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    json_data=json.dumps(brother_info)
    df=pd.read_json(json_data,orient="records")
    print(df)
```

总结：

在以上的例子中，可以发现在进行简单的格式转换的时候，可以使用 pandas 库的 read_json 进行处理，在进行复杂的格式转换的时候就要配合 json 库进行使用。无论是什么样的 json 数据，基本思路都是现将 json 文件读取进来，然后选择想要转换的数据，或是列表或是字典，然后再进行转换。

在这里重点介绍一下两个函数 read\_json 方法和 json\_normalize 方法。在使用时，要注意 read\_json 方法中 orient 参数的选择，同时 json\_normalize 可以将传入的列表、字典形式的 json 格式数据直接转换成 dataframe。

DataFrame 转为 json。通常情况下，我们使用的都是 pandas 中的 to\_json() 函数，可以通过设置 orient 参数来转换成为我们想要的 json 格式，orient 函数有以下几个参数："split", "records", "index", "columns", "values"。

1『后面的内容详见原文或者官方文档。』

## 02. 清洗物性数据

```
# 根据序号去重
df.drop_duplicates(['id'])

# 写进数据库
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://root@localhost:3306/shop')
df.to_sql('tz_property', engine, index= False)
```

清洗记录（2020-04-07）

基础数据 baseproperty.csv
```
%load_ext autoreload
%autoreload 2
import dalongmodule as dalong

df.loc[:,'hazard'] = df['hazard'].apply(lambda x: re.sub('\n', '\n\n', x))
df.loc[:,'hazard'] = df['hazard'].apply(lambda x: dalong.modify_text(x))

# 必须先转为字符串
df.loc[:,'cas'] = df['cas'].astype('str').apply(lambda x: re.sub('/', '-', x))

df.loc[:,'ename'] = df['ename'].astype('str').apply(lambda x: re.sub(';', '; ', x))
```

数据 casdata.csv


```
df.loc[:,'cas'] = df['cas'].astype('str').apply(lambda x: re.sub('/', '-', x))


# 合并数据，df1 是基础数据，df 是 msds
data = pd.merge(df1, df, on='cas', how='outer')

data = data.dropna(subset=['id'])
data = data.drop_duplicates(['id'])
```

```
ALTER TABLE `tz_property` MODIFY COLUMN `cname` VARCHAR(255) COMMENT '物质中文名称';
ALTER TABLE `tz_property` MODIFY COLUMN `alisname` VARCHAR(255) COMMENT '物质别名';
ALTER TABLE `tz_property` MODIFY COLUMN `cas` VARCHAR(255) COMMENT '物质 CAS 号';
ALTER TABLE `tz_property` MODIFY COLUMN `comment` VARCHAR(255) COMMENT '备注';
ALTER TABLE `tz_property` MODIFY COLUMN `special_warn` VARCHAR(255) COMMENT '特别警示';
```

如果只对对某列的所有非零值进行处理，可以用：

```
df.loc[:,'appearance'] = df[df['appearance'].notnull()].astype('str').apply(lambda x: '外观与性状：' + x)
```


## 代码

```py
# -*- coding:utf-8 -*-

from io import StringIO
import json, time, os.path, re, glob

import numpy as np
import pandas as pd
import docx
from docx import Document

def get_docxtable():
    """获取 word 内 table 数据"""
    document = Document('material.docx')
    tables = document.tables
    table = tables[0]

    materials = []

    for i in range(1, len(table.rows)):
        material = {}
        material['id'] = table.cell(i,0).text
        material['name'] = table.cell(i,1).text
        material['alisname'] = table.cell(i,2).text
        material['englishname'] = table.cell(i,3).text
        material['cas'] = table.cell(i,4).text
        material['hazard'] = table.cell(i,5).text
        material['comment'] = table.cell(i,6).text
        materials.append(material)

    # with open('materialdata.json', 'w',  encoding='utf-8') as f:
    with open('materialdata.json', 'w') as f:
        json.dump(materials, f)

def process_msds():
    df = pd.read_csv('20200407msds.csv')
    df['environment'] = df['content'].astype('str').apply(lambda x: re.search(r'(?s)(2\.)(.)*(3\.)', x).group() if re.search(r'2\.(?s)(.)*3\.', x) else '')
    df['emergency'] = df['content'].astype('str').apply(lambda x: re.search(r'(?s)(应急处理处置方法:)(.)*', x).group() if re.search(r'(?s)(应急处理处置方法:)(.)*', x) else '')
    # print(df1)
    df.to_csv('msds.csv', index=False)

if __name__ == '__main__':
    time_start = time.time()

    try:
        # get_docxtable()
        process_msds()
    except Exception as e:
        print('Error: ' + e)

    time_end = time.time()
    print('Time Used: ' + str(time_end-time_start) + 's')

```





