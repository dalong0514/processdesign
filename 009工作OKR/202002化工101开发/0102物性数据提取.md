# 物性数据

## 01. 物性数据

### 1. 危化品数据

从 word 里提取表格数据。

```py
# -*- coding:utf-8 -*-

from io import StringIO
import json, time, os.path, re, glob

import numpy as np
import pandas as pd
from sqlalchemy import create_engine
import docx
from docx import Document

def get_docxtable():
    """获取 word 内 table 数据"""
    document = Document('material.docx')
    tables = document.tables
    table = tables[0]

    materials = []

    for i in range(1, len(table.rows)):
        material = {}
        material['id'] = table.cell(i,0).text
        material['name'] = table.cell(i,1).text
        material['alisname'] = table.cell(i,2).text
        material['englishname'] = table.cell(i,3).text
        material['cas'] = table.cell(i,4).text
        material['hazard'] = table.cell(i,5).text
        material['comment'] = table.cell(i,6).text
        materials.append(material)

    # with open('materialdata.json', 'w',  encoding='utf-8') as f:
    with open('materialdata.json', 'w') as f:
        json.dump(materials, f)

    # 存储为 json 数据
    with open('data.json', 'w') as f:
        json.dump(materials, f)
    
    # 转成 dataframe 格式
    df = pd.read_json("data.json",encoding="utf-8", orient='records')

    # 写数据
    engine = create_engine('mysql+pymysql://root@localhost:3306/pandasdata')
    df.to_sql('materialdata', engine, index= False)

if __name__ == '__main__':
    time_start = time.time()

    try:
        get_docxtable()
    except Exception as e:
        print('Error: ' + e)

    time_end = time.time()
    print('Time Used: ' + str(time_end-time_start) + 's')

```

### 2. 重点监管物质

```py
def get_supervisedata():
    """获取重点监管物质数据"""
    document = Document('zhongdian.docx')
    tables = document.tables

    materials = []
    for table in tables:
        material = {}
        material['special_warn'] = table.cell(0,1).text
        material['physical_property'] = table.cell(1,1).text
        material['harm_info'] = table.cell(2,1).text
        material['safety_precaution'] = table.cell(3,1).text
        material['emergency'] = table.cell(4,1).text
        materials.append(material)

    with open('supervisedata.json', 'w', encoding='utf-8') as f:
        json.dump(materials, f)
```

进 jupyter 里加工。

```py
df = pd.read_json("supervisedata.json",encoding="utf-8", orient='records')
df.index = list(range(1,df.shape[0]+1))
df = df.reset_index()
df = df.rename(columns={'index':'supervise_id'})

# 增加危化品序号字段
data = pd.merge(df, df1, on='supervise_id', how='outer')

df.to_csv('supervisedata.csv', index=False)

# 与原有数据合并
df = pd.merge(df, data, on='id', how='outer')
df = df.drop_duplicates(['id'])

df.to_csv('20200413property.csv', index=False)

# 通过判断是否为空值选择性的赋值
df['supervise_status'] = df['supervise_id'].apply(lambda x: 0 if pd.isna(x) else 1)

# 合并两列的字符串
df.loc[:,'emergency'] = df['emergency_y'].astype('str') + df['emergency_x'].astype('str')

# 写数据
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://root@localhost:3306/shop')
df.to_sql('tz_property', engine, index= False)
```

### 3. 国家危险废物目录

```py
def get_harmdata():
    """获取 word 内 table 数据"""
    document = Document('data.docx')
    tables = document.tables
    table = tables[0]

    materials = []

    for i in range(1, len(table.rows)):
        material = {}
        material['harm-category'] = table.cell(i,0).text
        material['industy-source'] = table.cell(i,1).text
        material['harm-code'] = table.cell(i,2).text
        material['harm-material'] = table.cell(i,3).text
        material['harm-feature'] = table.cell(i,4).text
        materials.append(material)

    with open('harmdata.json', 'w', encoding='utf-8') as f:
        json.dump(materials, f)
```

进 jupyter 里加工。

```py
df = pd.read_json("harmdata.json",encoding="utf-8", orient='records')

# 去换行符
df['harm-category-modify'] = df['harm-category'].apply(lambda x: x.replace('\n', ''))

# 拆解
df['hw'] =  df['harm-category-modify'].apply(lambda x: re.search('(HW[0-9]+).*', x).group())
df['harm-modify'] = df['harm-category-modify'].apply(lambda x: re.search('(HW[0-9]+)(.*)', x).group(2))
df['hw-id'] = df['hw'].apply(lambda x: re.search('(HW)0?([1-9][0-9]?).*', x).group(2))

# 重新清洗
df.loc[:,'harm-category-modify'] = df['harm-category-modify'].apply(lambda x: re.search('(HW.*)?(HW.*)', x).group(2))
df['harm-modify'] = df['harm-category-modify'].apply(lambda x: re.search('(HW[0-9]+)(.*)', x).group(2))
df.loc[:,'harm-category'] = df['hw'] + '\n' + df['harm-modify']

df['hw'] = df['harm-category-modify'].apply(lambda x: re.search('(HW[0-9]+)(.*)', x).group(1))

# 格式规整
df.loc[:,'harm-category-modify'] = df['harm-category-modify'].apply(lambda x: dalong.modify_text(x))

# 导出数据
df.to_csv('20200506harm-data.csv', index=False)

# 写数据
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://root@localhost:3306/shop')
df.to_sql('tz_harmdata', engine, index= False)
```

进数据库里更改数据类型。

```
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-category` VARCHAR(255) COMMENT '废物类别';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `industy-source` VARCHAR(255) COMMENT '行业来源';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-code` VARCHAR(255) COMMENT '废物代码';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-material` VARCHAR(255) COMMENT '危险废物';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-feature` VARCHAR(255) COMMENT '废物类别';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-category-modify` VARCHAR(255) COMMENT '废物类别修改';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `hw` VARCHAR(255) COMMENT '废物类别代号';
ALTER TABLE `tz_harmdata` MODIFY COLUMN `harm-modify` VARCHAR(255) COMMENT '废物类别修改名称';
```

重要注意点：小程序里的变量名识别不了连号「-」，所以所有数据库的字段改为下划线，直接在数据库里改。

1、具有下列情形之一的固体废物（包括液态废物），列入本名录：

1）具有腐蚀性、毒性、易燃性、反应性或者感染性等一种或者几种危险特性的；

2）不排除具有危险特性，可能对环境或者人体健康造成有 害影响，需要按照危险废物进行管理的。

2、医疗废物属于危险废物。医疗废物分类按照《医疗废物分类目录》执行。

3、列入《危险化学品目录》的化学品废弃后属于危险废物。

4、列入本名录附录《危险废物豁免管理清单》中的危险废物，在所列的豁免环节，且满足相应的豁免条件时，可以按照豁免内容的规定实行豁免管理。

5、危险废物与其他固体废物的混合物，以及危险废物处理后的废物的属性判定，按照国家规定的危险废物鉴别标准执行。

6、本名录中有关术语的含义如下：

1）废物类别，是在《控制危险废物越境转移及其处置巴塞尔公约》划定的类别基础上，结合我国实际情况对危险废物进行的分类。

2）行业来源，是指危险废物的产生行业。

3）废物代码，是指危险废物的唯一代码，为 8 位数字。其 中，第 1-3 位为危险废物产生行业代码（依据《国民经济行业分类 （GB/T 4754-2011）》确定），第 4-6 位为危险废物顺序代码，第 7-8 位为危险废物类别代码。

4）危险特性，包括腐蚀性（Corrosivity, C）、毒性（Toxicity, T）、易燃性（Ignitability, I）、反应性（Reactivity, R）和感染性（Infectivity, In）。

7、对不明确是否具有危险特性的固体废物，应当按照国家规定的危险废物鉴别标准和鉴别方法予以认定。经鉴别具有危险特性的，属于危险废物，应当根据其主要有害成分和危险特性确定所属废物类别，并按代码「900-000-××」（×× 为危 险废物类别代码）进行归类管理。经鉴别不具有危险特性的，不属于危险废物。

## 02. 过程中遇到的问题

### 01

word 要另存为 2007 版的 docx 文件，否则读不出来。

官方文档有关表格的知识：[Quickstart — python-docx 0.8.10 documentation](https://python-docx.readthedocs.io/en/latest/user/quickstart.html)。

### 02

json 转成 dataframe 格式数据有很多知识点。

[python 中基于 pandas 模块：json 与 dataframe 的互相转换](https://blog.csdn.net/qq_41780234/article/details/84990551)

[pandas.read_json — pandas 1.0.3 documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html#pandas.read_json)

当我们在进行数据分析的时候，经常会遇到各种各样格式的文件，今天在这里整理一下对于 json 格式的文件怎么转化为 dataframe 的形式的文件。

1、对于简单的 json 形式。所谓的简单的 json 格式，就是将字典形式的文件，直接输出成 dataframe 形式的文件。test.json：

```py
obj="""[{"姓名": "张三",
 "住处": "天朝",
 "宠物": "koala",
 "兄弟": "李四"
},{"姓名": "李四",
 "住处": "天朝",
 "宠物": "cat",
 "兄弟": "张三"}]"""

with open("test.json","w",encoding="utf-8") as f:
    f.write(obj)
```

利用 pandas 自带的 read_json 直接解析字符串。

```py
import pandas as pd
df = pd.read_json("test.json",encoding="utf-8", orient='records')
print(df)
```

利用 json 库 loads 方法和 pandas 库中的 json_normalize 方法。

```py
import json 
from pandas.io.json import json_normalize
data=open("test.json",encoding="utf-8").read()
data_list = json.loads(data)
df = json_normalize(data_list)
print(df)
```

2、对于稍微复杂一些的 json 进行处理。复杂的一些的 json 格式的文件，例子如下，我们想要得到的数据是张三兄弟的数据，同样先写入 json 文件：

```py
obj = """
{"姓名": "张三",
 "住处": ["天朝", "岛国", "万恶的资本主义日不落帝国"],
 "宠物": null,
 "兄弟": [{"姓名": "李四", "年龄": 25, "宠物": "汪星人"},
              {"姓名": "王五", "年龄": 23, "宠物": "喵星人"}]
}"""
with open("test1.json","w",encoding="utf-8") as f:
    f.write(obj)
```

利用 json 的 loads 和 pandas 的 DataFrame。

```py
import json 
import pandas as pd
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    df=pd.DataFrame(brother_info)
#     print(type(brother_info))
#     print(brother_info)
#     print(brother_info)
```

利用 json 的 loads 和 pandas 的 json_normalize。

```py
from pandas.io.json import json_normalize
import json 
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    df = json_normalize(brother_info)
    print(df)
```

利用 json 的 loads 和 pandas 的 read_json。

```py
import json 
import pandas as pd
with open("test1.json","r",encoding="utf-8") as f:
    info=f.read()
    data_list = json.loads(info)
    brother_info = data_list["兄弟"]
    json_data=json.dumps(brother_info)
    df=pd.read_json(json_data,orient="records")
    print(df)
```

总结：

在以上的例子中，可以发现在进行简单的格式转换的时候，可以使用 pandas 库的 read_json 进行处理，在进行复杂的格式转换的时候就要配合 json 库进行使用。无论是什么样的 json 数据，基本思路都是现将 json 文件读取进来，然后选择想要转换的数据，或是列表或是字典，然后再进行转换。

在这里重点介绍一下两个函数 read\_json 方法和 json\_normalize 方法。在使用时，要注意 read\_json 方法中 orient 参数的选择，同时 json\_normalize 可以将传入的列表、字典形式的 json 格式数据直接转换成 dataframe。

DataFrame 转为 json。通常情况下，我们使用的都是 pandas 中的 to\_json() 函数，可以通过设置 orient 参数来转换成为我们想要的 json 格式，orient 函数有以下几个参数："split", "records", "index", "columns", "values"。

1『后面的内容详见原文或者官方文档。』

## 02. 清洗物性数据

```
# 根据序号去重
df.drop_duplicates(['id'])

# 写进数据库
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://root@localhost:3306/shop')
df.to_sql('tz_property', engine, index= False)
```

清洗记录（2020-04-07）

基础数据 baseproperty.csv
```
%load_ext autoreload
%autoreload 2
import dalongmodule as dalong

df.loc[:,'hazard'] = df['hazard'].apply(lambda x: re.sub('\n', '\n\n', x))
df.loc[:,'hazard'] = df['hazard'].apply(lambda x: dalong.modify_text(x))

# 必须先转为字符串
df.loc[:,'cas'] = df['cas'].astype('str').apply(lambda x: re.sub('/', '-', x))

df.loc[:,'ename'] = df['ename'].astype('str').apply(lambda x: re.sub(';', '; ', x))
```

数据 casdata.csv


```
df.loc[:,'cas'] = df['cas'].astype('str').apply(lambda x: re.sub('/', '-', x))


# 合并数据，df1 是基础数据，df 是 msds
data = pd.merge(df1, df, on='cas', how='outer')

data = data.dropna(subset=['id'])
data = data.drop_duplicates(['id'])
```

```
ALTER TABLE `tz_property` MODIFY COLUMN `cname` VARCHAR(255) COMMENT '物质中文名称';
ALTER TABLE `tz_property` MODIFY COLUMN `alisname` VARCHAR(255) COMMENT '物质别名';
ALTER TABLE `tz_property` MODIFY COLUMN `cas` VARCHAR(255) COMMENT '物质 CAS 号';
ALTER TABLE `tz_property` MODIFY COLUMN `comment` VARCHAR(255) COMMENT '备注';
ALTER TABLE `tz_property` MODIFY COLUMN `special_warn` VARCHAR(255) COMMENT '特别警示';
```

如果只对对某列的所有非零值进行处理，可以用：

```
df.loc[:,'appearance'] = df[df['appearance'].notnull()].astype('str').apply(lambda x: '外观与性状：' + x)
```

## 代码

```py
# -*- coding:utf-8 -*-

from io import StringIO
import json, time, os.path, re, glob

import numpy as np
import pandas as pd
import docx
from docx import Document

def get_docxtable():
    """获取 word 内 table 数据"""
    document = Document('material.docx')
    tables = document.tables
    table = tables[0]

    materials = []

    for i in range(1, len(table.rows)):
        material = {}
        material['id'] = table.cell(i,0).text
        material['name'] = table.cell(i,1).text
        material['alisname'] = table.cell(i,2).text
        material['englishname'] = table.cell(i,3).text
        material['cas'] = table.cell(i,4).text
        material['hazard'] = table.cell(i,5).text
        material['comment'] = table.cell(i,6).text
        materials.append(material)

    # with open('materialdata.json', 'w',  encoding='utf-8') as f:
    with open('materialdata.json', 'w') as f:
        json.dump(materials, f)

def process_msds():
    df = pd.read_csv('20200407msds.csv')
    df['environment'] = df['content'].astype('str').apply(lambda x: re.search(r'(?s)(2\.)(.)*(3\.)', x).group() if re.search(r'2\.(?s)(.)*3\.', x) else '')
    df['emergency'] = df['content'].astype('str').apply(lambda x: re.search(r'(?s)(应急处理处置方法:)(.)*', x).group() if re.search(r'(?s)(应急处理处置方法:)(.)*', x) else '')
    # print(df1)
    df.to_csv('msds.csv', index=False)

if __name__ == '__main__':
    time_start = time.time()

    try:
        # get_docxtable()
        process_msds()
    except Exception as e:
        print('Error: ' + e)

    time_end = time.time()
    print('Time Used: ' + str(time_end-time_start) + 's')

```
